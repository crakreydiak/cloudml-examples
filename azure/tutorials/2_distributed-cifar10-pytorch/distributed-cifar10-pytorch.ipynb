{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this tutorial, you can re-use the environment defined in the [previous tutorial](../1_mnist-pytorch-lit/mnist-pytorch-lit.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequesites\n",
    "1. An Azure subscription. If you don't have on, you can [create a free account](https://aka.ms/AMLFree).\n",
    "2. An active Azure Resource Group. Create one [here](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/manage-resource-groups-portal) or re-use an existing resource group.\n",
    "3. A working Azure ML Workspace. Create one [here](https://learn.microsoft.com/en-us/azure/machine-learning/concept-workspace#create-a-workspace) or re-use an existing workspace.\n",
    "4. **An active account with at least 20 cores**. Follow the instructions [here](https://learn.microsoft.com/en-us/azure/quotas/per-vm-quota-requests) to increase your quota.\n",
    "5. A CPU compute environment.\n",
    "6. A GPU compute environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the previous tutorial, we trained a MNIST classifier using Azure Python SDK. One bottleneck was the wait time between jobs. More specifically, we had to wait for the data to upload before training the classifier. Azure can help automate this process using pipelines. We can set different steps for the different jobs that use their own compute environments. For instance, we can re-use our CPU cluster to upload the data, train the model in a distributed manner on a multi-gpu cluster and finally test it on the less expensive CPU cluster."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to your Azure Workspace\n",
    "\n",
    "Switching between workspaces or resource groups during an active session can cause authentification issues. The following cell attempts to load a token using the default authentification and falls back to the browser option if the former fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "try:\n",
    "    cred = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully\n",
    "    cred.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as e:\n",
    "    # Fall back to browser authentification\n",
    "    cred = InteractiveBrowserCredential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, we used a dotenv file to store and load sensitive information. Alternatively, we can create a json configuration file in a predefined path that Azure will load automatically. This prevents us from installing unecessary libraries. The following cell copies the default configuration file. You can then replace the default values with yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "!cp .azureml/config.example.json .azureml/config.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to your workspace and load the compute clusters. We assume the CPU and GPU clusters were already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient.from_config(\n",
    "    credential=cred,\n",
    ")\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "gpu_cluster_name = \"gpu-cluster\"\n",
    "\n",
    "# will fail if one of the compute environments does not exist\n",
    "print(f\"CPU Cluster: {ml_client.compute.get(cpu_cluster_name)}\")\n",
    "print(f\"GPU Cluster: {ml_client.compute.get(gpu_cluster_name)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the data\n",
    "\n",
    "Run the [download script](get-data/download.ps1) using Powershell to download a copy of CIFAR-10. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define command components in YAML\n",
    "\n",
    "Azure provides the utility function `load_component` which parses the YAML configuration job into an executable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_component\n",
    "\n",
    "parent_dir = \".\"\n",
    "get_data_func = load_component(source=parent_dir + \"/get-data.job.yaml\")\n",
    "train_model_func = load_component(source=parent_dir + \"/train-model.job.yaml\")\n",
    "eval_model_func = load_component(source=parent_dir + \"/eval-model.job.yaml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build and launch the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "@pipeline()\n",
    "def train_cifar_pytorch():\n",
    "    # define the data job\n",
    "    data_job = get_data_func(\n",
    "        cifar_tar=Input(\n",
    "            path=\"wasbs://datasets@azuremlexamples.blob.core.windows.net/cifar-10-python.tar.gz\",\n",
    "            type=\"uri_file\",\n",
    "        )\n",
    "    )\n",
    "    data_job.outputs.cifar.mode = \"upload\"\n",
    "\n",
    "    # define the training job\n",
    "    training_job = train_model_func(\n",
    "        max_epochs=5,\n",
    "        path_to_data=data_job.outputs.cifar,\n",
    "        num_workers=4,\n",
    "        batch_size=16,\n",
    "    )\n",
    "    training_job.compute = \"gpu-cluster\"\n",
    "    training_job.outputs.path_to_model.mode = \"upload\"\n",
    "\n",
    "    # define the evaluation job\n",
    "    eval_job = eval_model_func(\n",
    "        cifar=data_job.outputs.cifar,\n",
    "        path_to_model=training_job.outputs.path_to_model\n",
    "    )\n",
    "\n",
    "pipeline_job = train_cifar_pytorch()\n",
    "pipeline_job.settings.default_compute = \"cpu-cluster\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"pipeline_cifar10_pytorch\"\n",
    "\n",
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Expected output](media/pipeline_cifar10_pytorch_expected.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important**:\n",
    "> Your default subscription might be limited to 6 vCPUs. To increase your quotas, follow the official instructions [here](https://learn.microsoft.com/en-us/azure/quotas/per-vm-quota-requests)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:42:03) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d629024c1c74c8a5195a1b34a926f6449533d06bb28d2b27f751f71fdee1c2c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
