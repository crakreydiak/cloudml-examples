{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This tutorial assumes you have a conda environment with the dependencies described in [env.yaml](env.yaml).  The following cell creates this environment. You then need to activate it in your IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "!conda env create -f env.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequesites\n",
    "1. An Azure subscription. If you don't have on, you can [create a free account](https://aka.ms/AMLFree).\n",
    "2. An active Azure Resource Group.\n",
    "3. A working Azure ML Workspace.\n",
    "\n",
    "The following steps help you set up [2]() and [3](). If these resources already exist, you can skip this cell. Visit [this link](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace-cli?tabs=createnewresources) for more information on how to manage your AML workspace using Azure CLI.\n",
    "\n",
    "In the following example, a new workspace named `mnist-pytorch-lit-ws` is attached to the new resource group `your_name-rg` located in `east-us`. The shell used is powershell, but the same command can be executed in bash for MacOS and Linux users. To install Azure CLI, [click here](https://learn.microsoft.com/en-us/cli/azure/) and follow the instructions.\n",
    "\n",
    "\n",
    "```powershell\n",
    "# add the \"azure-cli-ml\" extension\n",
    "!az extension add --name azure-cli-ml`\n",
    "# login to azure (will open a browser for authentification)\n",
    "!az login\n",
    "# create a resource group named \"your_name-rg\"\n",
    "!az group create --name your_name-rg --location eastus --tags env=tutorial\n",
    "# create a workspace named \"mnist-pytorch-lit-ws\" attached to resource group \"your_name-rg\"\n",
    "!az ml workspace create -w mnist-pytorch-lit-ws -g your_name-rg --tags env=tutorial\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important**:\n",
    "> When you deploy an Azure Machine Learning workspace, various [other services are created by default](https://learn.microsoft.com/en-us/azure/machine-learning/concept-workspace#associated-resources). Theses services include an [Azure Storage Account](https://azure.microsoft.com/en-us/products/category/storage/) used to store models, checkpoints and our most importantly the training data. Depending on your needs, you might want to create the storage account ahead of time and link it to the workspace. For ML workflows, Microsoft recommands [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs/), the \"massively scalable and secure object storage\". Visit the [official documentation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-datastore?tabs=sdk-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access) to learn how to programmatically create datastores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your Azure Workspace\n",
    "\n",
    "The interactions with your workspace abstracted through a `azure.ai.ml.MLClient` object. It requires an authentification method, the ID of your subscription and the names of your resource group and workspace. We use `DefaultAzureCredential` to gain access to the workspace but alternatively the `InteractiveBrowserCredential` can be used if you prefer using a browser to authenticate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace client\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentification package\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "cred = DefaultAzureCredential()\n",
    "# uncomment to use the InteractiveBrowserCredential instead\n",
    "# from azure.identity import InteractiveBrowserCredential\n",
    "# cred = InteractiveBrowserCredential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your subscription ID, the names of your resource group and workspace, we can now create a workspace handler. We store privileged information using environment variables and the `python-dotenv` package. The environment variables are defined a file named `.env` that you must create. The following cell copies the basic template `.env.example`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "!cp .env.example .env"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your subscription ID in `.env`. Now load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# change the values in .env if needed\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = os.getenv(\"AZURE_SUBSCRIPTION_ID\") # set the value in `.env`\n",
    "azure_RG = os.getenv(\"AZURE_RESOURCE_GROUP\") # matches the name of the resource group we created\n",
    "azure_WS = os.getenv(\"AZURE_WORKSPACE\")  # matches the name of the workspace we created\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=cred,\n",
    "    subscription_id=sub_id,\n",
    "    resource_group_name=azure_RG,\n",
    "    workspace_name=azure_WS\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create compute resources to run jobs\n",
    "Cloud-based tasks are specified by jobs that run on various VMs. In this tutorial, we'll need two clusters: a basic CPU to upload our local data and a GPU cluster to run the training job. Multiple choice of architectures [are available here](https://azure.microsoft.com/en-us/pricing/details/machine-learning/) but beware of subscription restrictions that can limit your options to basic VMs. Free accounts are limit to single-GPU VMs and 6 vCPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "cpu_compute_target = \"cpu-cluster\"\n",
    "\n",
    "# Checks if the resource exists and creates it if not.\n",
    "# An `if` statement would be better, but since there is currently no `exists` method, \n",
    "# we need this try/catch statement \n",
    "try: \n",
    "    # throw an exception if the resource does not exist\n",
    "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
    "    print(f\"Found existing cluster {cpu_compute_target}.\")\n",
    "except ResourceNotFoundError:\n",
    "    print(\"Creating a new cpu compute target...\")\n",
    "    cpu_cluster = AmlCompute(\n",
    "        # Name of the cluster\n",
    "        name=cpu_compute_target,\n",
    "        # Azure ML Compute is the on-demand VM service\n",
    "        type=\"amlcompute\",\n",
    "        # VM Family\n",
    "        size=\"STANDARD_DS3_V2\",\n",
    "        # Minimum running nodes when there is no job running\n",
    "        min_instances=0,\n",
    "        # Nodes in the cluster\n",
    "        max_instances=4,\n",
    "        # How many seconds will the node running after the job termination\n",
    "        idle_time_before_scale_down=180,\n",
    "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "    # Create the cluster\n",
    "    cpu_cluster = ml_client.begin_create_or_update(cpu_cluster).result()\n",
    "\n",
    "print(f\"AMLCompute with name {cpu_cluster.name} is used with compute size {cpu_cluster.size}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GPUs, we create the cluster from the smallest possible VM family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "gpu_compute_target = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    # let's see if the compute target already exists\n",
    "    gpu_cluster = ml_client.compute.get(gpu_compute_target)\n",
    "    print(\n",
    "        f\"You already have a cluster named {gpu_compute_target}, we'll reuse it as is.\"\n",
    "    )\n",
    "\n",
    "except Exception:\n",
    "    print(\"Creating a new gpu compute target...\")\n",
    "\n",
    "    gpu_cluster = AmlCompute(\n",
    "        name=\"gpu-cluster\",\n",
    "        type=\"amlcompute\",\n",
    "        size=\"STANDARD_NC6\",  # 1 x NVIDIA Tesla K80 ($0.90 USD per hour)\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        idle_time_before_scale_down=180,\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "\n",
    "    gpu_cluster = ml_client.begin_create_or_update(gpu_cluster).result()\n",
    "\n",
    "print(\n",
    "    f\"AMLCompute with name {gpu_cluster.name} is created with the compute size {gpu_cluster.size}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important**.\n",
    "> During the writing of this tutorial, I learned that Microsoft intends to decommission their NC, NCv2 and ND-series VMs in favor of new hardware by the end of 2023. Their [migration guide](https://learn.microsoft.com/en-us/azure/virtual-machines/n-series-migration) recommands upgrading to `Standard_NC4as_T4_v3` or `Standard_NC8as_T4` VMs. However, these options are unavailable to new accounts. You need to [request more quotas](https://learn.microsoft.com/en-us/azure/quotas/per-vm-quota-requests) and have access to at least 20 cores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Upload the data\n",
    "\n",
    "We train a basic PyTorch Lightning MLP classifier on the well-known MNIST dataset. We could download the dataset using a public URL during training, but this would increase the time usage of our most expensive hardware. Alternatively, we can submit a job to download the data from the same URL. In production, we would probably skip this step entirely since the data will already be stored somewhere in Azure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training and test data \n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import os\n",
    "\n",
    "# create local folder to store data\n",
    "os.makedirs(\"./data\", exist_ok=\"ok\")\n",
    "\n",
    "# download training data\n",
    "train_data = MNIST(\n",
    "    \"./data/train\",\n",
    "    train=True, download=True,\n",
    ")\n",
    "# download test data\n",
    "test_data = MNIST(\n",
    "    \"./data/test\",\n",
    "    train=False, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# create archive\n",
    "!tar -czvf mnist.tar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "experiment_name = \"train_mnist_pytorch-lit\"\n",
    "\n",
    "# we define the command here and submit it in the next cell\n",
    "upload_dataset_job = command(\n",
    "    display_name=\"upload_mnist\",\n",
    "    command=\"tar xvfm ${{inputs.archive}} --no-same-owner -C ${{outputs.images}}\",\n",
    "    inputs={\n",
    "        \"archive\": Input(\n",
    "            type=AssetTypes.URI_FILE,\n",
    "            path=\"mnist.tar\"\n",
    "        )\n",
    "    },\n",
    "    outputs={\n",
    "        \"images\": Output(\n",
    "            type=AssetTypes.URI_FOLDER,\n",
    "            mode=\"upload\",\n",
    "            # path must begin with `azureml://` and must point to a cloud path\n",
    "            path=\"azureml://datastores/workspaceblobstore/paths/mnist-pytorch-lit-tutorial\"\n",
    "        )\n",
    "    },\n",
    "    # an existing environment with pre-installed libraries\n",
    "    # we can create our own for the current purposes we can re-use an existing one\n",
    "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
    "    # the cpu compute resource we just created\n",
    "    compute=cpu_compute_target,\n",
    "    # assemble jobs under the same experiment\n",
    "    experiment_name=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.create_or_update(\n",
    "    upload_dataset_job,\n",
    ")\n",
    "\n",
    "# get a URL for the status of the job\n",
    "print(\"The url to see your live job running is returned by the sdk:\")\n",
    "print(returned_job.studio_url)\n",
    "# open the browser with this url\n",
    "webbrowser.open(returned_job.studio_url)\n",
    "\n",
    "# print the pipeline run id\n",
    "print(\n",
    "    f\"The pipeline details can be access programmatically using identifier: {returned_job.name}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task might take a few minutes to complete. You can track its progress on Azure Portal. By default, Azure will have created four different datastores. The files should be stored in the `workspacedatablob`. You can browse this storage device by accessing `Assets > Data > Datastores` in your [Microsoft Azure Machine Learning Studio](https://ml.azure.com/) interface. Your output should be similar to this:\n",
    "\n",
    "![expected result](media/azure-upload-job-result.png )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a custom training environment\n",
    "When developing locally, we generally define a Python virtual environment to define the dependencies of our project. Azure provides [environments](https://docs.microsoft.com/azure/machine-learning/concept-environments) to specify the dependencies. They can be created in three different ways:\n",
    "\n",
    "1. By using a curated environment.\n",
    "2. By creating a custom environment from a Docker image.\n",
    "3. By creating a custom environment from a conda specification and a pre-existing Docker image.\n",
    "\n",
    "AzureML provides many curated or ready-made environments, which are useful for common training and inference scenarios. However, these contain only basic dependencies. A list of existing curated environments can be found [here](https://learn.microsoft.com/en-us/azure/machine-learning/resource-curated-environments) or from the Environments tab in Azure Machine Learning Studio. You can also create your own custom environments using a Docker image, or a conda configuration. Regular Docker images don't have access to hardware acceleration so you must select specific images provided by Nvidia and [Azure](https://learn.microsoft.com/en-us/azure/machine-learning/concept-prebuilt-docker-images-inference). \n",
    "\n",
    "In this example, we use a custom conda environment for the training job, using a conda yaml file. More information about environment management can be found [here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-environments-v2?tabs=python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "import os \n",
    "\n",
    "custom_env_name = \"mnist-pytorch-lit-env\"\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    # name of the environment\n",
    "    name=custom_env_name,\n",
    "    # short description of the environmenttas\n",
    "    description=\"Custom environment for the MNIST PytorchLit tutorial\",\n",
    "    # tags \n",
    "    tags={\"pytorch\": \"1.12\", \"cuda\": \"11.6\"},\n",
    "    # path to the conda environment file\n",
    "    conda_file=\"env.yaml\",\n",
    "    # URI of a custom-based image, here we use an existing image with GPU support\n",
    "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-1.12-py38-cuda11.6-gpu:4\",\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"\"\"Environment with name {pipeline_job_env.name} is registered to workspace,\n",
    "     the environment version is {pipeline_job_env.version}\"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create and submit the training command job\n",
    "Using the environment created in the previous step, we can now define the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "training_job = command(\n",
    "    # local path to the source code\n",
    "    code=\"./src/\",\n",
    "    # the commands to run the python script\n",
    "    command=\"\"\"python train.py \\\n",
    "        --path_to_data ${{inputs.path_to_data}} \\\n",
    "        --batch_size ${{inputs.batch_size}} \\\n",
    "        --max_epochs ${{inputs.max_epochs}} \\\n",
    "        --num_workers ${{inputs.num_workers}} \\\n",
    "        --hidden_dim ${{inputs.hidden_dim}} \\\n",
    "    \"\"\",\n",
    "    # inject variables to the command above\n",
    "    inputs={\n",
    "        \"path_to_data\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"azureml://datastores/workspaceblobstore/paths/mnist-pytorch-lit-tutorial/data\",\n",
    "            mode=\"download\" # use `download` to make access faster, `mount` if dataset is larger than VM\n",
    "        ),\n",
    "        \"batch_size\": 32,\n",
    "        \"max_epochs\": 5,\n",
    "        \"num_workers\": 5,\n",
    "        \"hidden_dim\": 3,\n",
    "    },\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        # set process count to the number of gpus on the node\n",
    "        # NC6 has only one\n",
    "        \"process_count_per_instance\": 1\n",
    "    },\n",
    "    # you can create multiple versions of the same environment, use @latest to fetch the latest one\n",
    "    environment=f\"{custom_env_name}@latest\",\n",
    "    # the name of compute infrastructure needed\n",
    "    compute=gpu_compute_target,\n",
    "    # set instance count to the number of nodes you want to use (1 * 6vCPUs)\n",
    "    # ***to use more resources, you will need to increase your quotas***\n",
    "    # https://learn.microsoft.com/en-us/azure/quotas/per-vm-quota-requests\n",
    "    # for the moment we leave it to the smallest possible value so that new accounts do not encounter quota limits\n",
    "    instance_count=1,\n",
    "    # assemble training job with upload job\n",
    "    experiment_name=experiment_name,\n",
    "    # friendly name displayed in tables (option)\n",
    "    display_name=\"MNIST PyTorchLit\",\n",
    "    # job description\n",
    "    description=\"Training a MLP classifier on MNIST dataset\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    training_job,\n",
    "    experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "# get a URL for the status of the job\n",
    "print(\"The url to see your live job running is returned by the sdk:\")\n",
    "print(returned_job.studio_url)\n",
    "# open the browser with this url\n",
    "webbrowser.open(returned_job.studio_url)\n",
    "\n",
    "# print the pipeline run id\n",
    "print(\n",
    "    f\"The pipeline details can be access programmatically using identifier: {returned_job.name}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important**:\n",
    "> Your default subscription might be limited to 6 vCPUs. To increase your quotas, follow the official instructions [here](https://learn.microsoft.com/en-us/azure/quotas/per-vm-quota-requests)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![expected result](media/azure-training-job-preparing.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the job is executed, it goes through the following stages:\n",
    "\n",
    "**Preparing**: A docker image is created according to the environment defined. The image is uploaded to the workspace's container registry and cached for later runs. Logs are also streamed to the job history and can be viewed to monitor progress. If a curated environment is specified, the cached image backing that curated environment will be used.\n",
    "\n",
    "**Scaling**: The cluster attempts to scale up if it requires more nodes to execute the run than are currently available.\n",
    "\n",
    "**Running**: All scripts in the script folder *src* are uploaded to the compute target, data stores are mounted or copied, and the script is executed. Outputs from *stdout* and the *./logs* folder are streamed to the job history and can be used to monitor the job."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "The following cells remove the created workspace and resource group. We will not delete your subscription since you would likely also lose your free credits. Deleting a resource group also removes its child resources (workspaces, storage accounts, key vaults, container registries, etc.). To help familiarize yourself with Azure CLI we delete the workspace before deleting its parent resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# delete the workspace\n",
    "!az ml workspace delete --name mnist-pytorch-lit-ws\n",
    "\n",
    "# delete the resource group\n",
    "!az group delete --name mnist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml-pytorch-lit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:42:03) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9af0f138276ae972c816011ec06a4177d1defc78aae721b9cf79bb01e6f5bdfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
